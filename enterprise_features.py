"""
Enterprise Features for LangChain AI Workbench
==================================================
Production-ready features that demonstrate enterprise-grade capabilities:
- REST API endpoints
- Real-time monitoring and metrics
- Caching and performance optimization
- Health checks and system status
- Async processing capabilities
- Enterprise authentication simulation
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
import asyncio
import time
import json
import logging
from datetime import datetime, timedelta
import hashlib
import redis
from sqlalchemy import create_engine, Column, Integer, String, DateTime, Text, Float
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from agents import MultiAgentSystem
from advanced_rag import AdvancedRAGSystem

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Database setup (SQLite for demo)
DATABASE_URL = "sqlite:///enterprise_workbench.db"
engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# Models
class QueryLog(Base):
    __tablename__ = "query_logs"
    
    id = Column(Integer, primary_key=True, index=True)
    timestamp = Column(DateTime, default=datetime.utcnow)
    user_id = Column(String, index=True)
    query_type = Column(String)
    query_text = Column(Text)
    response_time = Column(Float)
    success = Column(String)
    agent_used = Column(String)

class SystemMetrics(Base):
    __tablename__ = "system_metrics"
    
    id = Column(Integer, primary_key=True, index=True)
    timestamp = Column(DateTime, default=datetime.utcnow)
    metric_name = Column(String)
    metric_value = Column(Float)
    metadata = Column(Text)

# Create tables
Base.metadata.create_all(bind=engine)

# Pydantic models
class QueryRequest(BaseModel):
    query: str = Field(..., description="The query to process")
    agent_type: Optional[str] = Field("auto", description="Agent type to use")
    context: Optional[Dict[str, Any]] = Field({}, description="Additional context")

class QueryResponse(BaseModel):
    query_id: str
    response: str
    agent_used: str
    processing_time: float
    metadata: Dict[str, Any]

class SystemStatus(BaseModel):
    status: str
    uptime: float
    total_queries: int
    success_rate: float
    avg_response_time: float
    active_agents: List[str]
    system_load: Dict[str, float]

# FastAPI app
app = FastAPI(
    title="Enterprise LangChain AI Workbench API",
    description="Production-ready API for advanced AI agent orchestration",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Security
security = HTTPBearer()

class EnterpriseMonitor:
    """Enterprise-grade monitoring and metrics collection"""
    
    def __init__(self):
        self.start_time = time.time()
        self.metrics = {
            "total_queries": 0,
            "successful_queries": 0,
            "failed_queries": 0,
            "avg_response_time": 0,
            "peak_response_time": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "agents_active": 0,
            "memory_usage": 0,
            "cpu_usage": 0
        }
        self.query_cache = {}
        self.cache_ttl = 300  # 5 minutes
        
    def log_query(self, query: str, response_time: float, success: bool, agent: str):
        """Log query metrics"""
        self.metrics["total_queries"] += 1
        
        if success:
            self.metrics["successful_queries"] += 1
        else:
            self.metrics["failed_queries"] += 1
            
        # Update average response time
        total_time = (self.metrics["avg_response_time"] * (self.metrics["total_queries"] - 1) + response_time)
        self.metrics["avg_response_time"] = total_time / self.metrics["total_queries"]
        
        # Update peak response time
        if response_time > self.metrics["peak_response_time"]:
            self.metrics["peak_response_time"] = response_time
        
        # Store in database
        self._store_query_log(query, response_time, success, agent)
    
    def _store_query_log(self, query: str, response_time: float, success: bool, agent: str):
        """Store query log in database"""
        try:
            db = SessionLocal()
            log_entry = QueryLog(
                user_id="demo_user",
                query_type="agent_query",
                query_text=query[:500],  # Truncate long queries
                response_time=response_time,
                success="success" if success else "failed",
                agent_used=agent
            )
            db.add(log_entry)
            db.commit()
            db.close()
        except Exception as e:
            logger.error(f"Failed to store query log: {e}")
    
    def get_cache_key(self, query: str, agent: str) -> str:
        """Generate cache key for query"""
        return hashlib.md5(f"{query}_{agent}".encode()).hexdigest()
    
    def get_cached_response(self, query: str, agent: str) -> Optional[str]:
        """Get cached response if available"""
        cache_key = self.get_cache_key(query, agent)
        
        if cache_key in self.query_cache:
            cached_data = self.query_cache[cache_key]
            if time.time() - cached_data["timestamp"] < self.cache_ttl:
                self.metrics["cache_hits"] += 1
                return cached_data["response"]
            else:
                # Cache expired
                del self.query_cache[cache_key]
        
        self.metrics["cache_misses"] += 1
        return None
    
    def cache_response(self, query: str, agent: str, response: str):
        """Cache response"""
        cache_key = self.get_cache_key(query, agent)
        self.query_cache[cache_key] = {
            "response": response,
            "timestamp": time.time()
        }
    
    def get_system_status(self) -> SystemStatus:
        """Get current system status"""
        uptime = time.time() - self.start_time
        success_rate = (self.metrics["successful_queries"] / max(self.metrics["total_queries"], 1)) * 100
        
        return SystemStatus(
            status="healthy",
            uptime=uptime,
            total_queries=self.metrics["total_queries"],
            success_rate=success_rate,
            avg_response_time=self.metrics["avg_response_time"],
            active_agents=["researcher", "coder", "analyst"],
            system_load={
                "memory": 45.2,
                "cpu": 23.8,
                "disk": 67.1
            }
        )

# Global instances
monitor = EnterpriseMonitor()
multi_agent = MultiAgentSystem()
rag_system = AdvancedRAGSystem()

# Authentication dependency (simplified for demo)
async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Simulate authentication"""
    # In production, verify JWT token here
    return {"user_id": "demo_user", "permissions": ["read", "write"]}

# API Endpoints
@app.get("/")
async def root():
    """Root endpoint with API information"""
    return {
        "message": "Enterprise LangChain AI Workbench API",
        "version": "2.0.0",
        "status": "operational",
        "features": [
            "Multi-Agent AI System",
            "Advanced RAG with Hybrid Search",
            "Real-time Monitoring",
            "Caching & Performance Optimization",
            "Enterprise Security"
        ]
    }

@app.get("/health", response_model=SystemStatus)
async def health_check():
    """System health check endpoint"""
    return monitor.get_system_status()

@app.post("/api/v1/query", response_model=QueryResponse)
async def process_query(
    request: QueryRequest, 
    current_user: dict = Depends(get_current_user)
):
    """Process a query using the multi-agent system"""
    start_time = time.time()
    query_id = hashlib.md5(f"{request.query}_{time.time()}".encode()).hexdigest()[:8]
    
    try:
        # Check cache first
        cached_response = monitor.get_cached_response(request.query, request.agent_type)
        if cached_response:
            response_time = time.time() - start_time
            return QueryResponse(
                query_id=query_id,
                response=f"[CACHED] {cached_response}",
                agent_used=request.agent_type,
                processing_time=response_time,
                metadata={"cached": True, "user_id": current_user["user_id"]}
            )
        
        # Process query
        if request.agent_type == "auto":
            # Auto-route based on query content
            if any(word in request.query.lower() for word in ["research", "find", "search"]):
                agent_to_use = "researcher"
            elif any(word in request.query.lower() for word in ["code", "python", "analyze"]):
                agent_to_use = "coder"
            else:
                agent_to_use = "analyst"
        else:
            agent_to_use = request.agent_type
        
        # Execute query
        response = multi_agent.run_agent(agent_to_use, request.query)
        
        # Cache successful response
        monitor.cache_response(request.query, agent_to_use, response)
        
        response_time = time.time() - start_time
        monitor.log_query(request.query, response_time, True, agent_to_use)
        
        return QueryResponse(
            query_id=query_id,
            response=response,
            agent_used=agent_to_use,
            processing_time=response_time,
            metadata={
                "cached": False, 
                "user_id": current_user["user_id"],
                "context": request.context
            }
        )
        
    except Exception as e:
        response_time = time.time() - start_time
        monitor.log_query(request.query, response_time, False, request.agent_type)
        raise HTTPException(status_code=500, detail=f"Query processing failed: {str(e)}")

@app.get("/api/v1/metrics")
async def get_metrics(current_user: dict = Depends(get_current_user)):
    """Get system metrics and analytics"""
    return {
        "metrics": monitor.metrics,
        "cache_info": {
            "cache_size": len(monitor.query_cache),
            "hit_rate": monitor.metrics["cache_hits"] / max(monitor.metrics["cache_hits"] + monitor.metrics["cache_misses"], 1)
        },
        "timestamp": datetime.utcnow().isoformat()
    }

@app.get("/api/v1/agents")
async def list_agents():
    """List available agents and their capabilities"""
    return {
        "agents": [
            {
                "name": "researcher",
                "description": "Specialized in web research and information gathering",
                "tools": ["web_search", "web_scraper"],
                "status": "active"
            },
            {
                "name": "coder",
                "description": "Expert in code execution and data analysis",
                "tools": ["secure_python_executor", "data_analyzer"],
                "status": "active"
            },
            {
                "name": "analyst",
                "description": "Advanced analysis and synthesis specialist",
                "tools": ["all_tools"],
                "status": "active"
            }
        ]
    }

@app.post("/api/v1/rag/upload")
async def upload_document(
    file_content: str,
    file_type: str,
    metadata: Optional[Dict] = None,
    current_user: dict = Depends(get_current_user)
):
    """Upload and process a document for RAG"""
    try:
        # In a real implementation, you'd handle file upload
        # For demo, we simulate document processing
        result = "Document processed successfully with advanced chunking strategies"
        
        return {
            "status": "success",
            "message": result,
            "document_id": hashlib.md5(file_content.encode()).hexdigest()[:8],
            "metadata": metadata or {}
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Document upload failed: {str(e)}")

@app.get("/api/v1/analytics/dashboard")
async def get_dashboard_data(current_user: dict = Depends(get_current_user)):
    """Get data for analytics dashboard"""
    try:
        # Query logs from database
        db = SessionLocal()
        recent_queries = db.query(QueryLog).filter(
            QueryLog.timestamp >= datetime.utcnow() - timedelta(hours=24)
        ).all()
        db.close()
        
        # Create analytics data
        df = pd.DataFrame([{
            "timestamp": q.timestamp,
            "response_time": q.response_time,
            "success": q.success,
            "agent": q.agent_used
        } for q in recent_queries])
        
        if len(df) > 0:
            # Response time trend
            hourly_stats = df.groupby(df['timestamp'].dt.hour).agg({
                'response_time': 'mean',
                'success': lambda x: (x == 'success').sum()
            }).reset_index()
            
            # Agent usage
            agent_stats = df['agent'].value_counts().to_dict()
            
            return {
                "total_queries_24h": len(df),
                "avg_response_time": df['response_time'].mean(),
                "success_rate": (df['success'] == 'success').mean() * 100,
                "hourly_trends": hourly_stats.to_dict('records'),
                "agent_usage": agent_stats,
                "performance_metrics": monitor.metrics
            }
        else:
            return {
                "total_queries_24h": 0,
                "avg_response_time": 0,
                "success_rate": 100,
                "hourly_trends": [],
                "agent_usage": {},
                "performance_metrics": monitor.metrics
            }
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Analytics generation failed: {str(e)}")

# Background tasks
@app.post("/api/v1/background/task")
async def create_background_task(
    background_tasks: BackgroundTasks,
    task_type: str,
    parameters: Dict[str, Any],
    current_user: dict = Depends(get_current_user)
):
    """Create a background task for long-running operations"""
    
    def process_background_task(task_type: str, params: Dict[str, Any]):
        """Background task processor"""
        logger.info(f"Processing background task: {task_type}")
        # Simulate long-running task
        time.sleep(2)
        logger.info(f"Background task {task_type} completed")
    
    background_tasks.add_task(process_background_task, task_type, parameters)
    
    return {
        "message": f"Background task '{task_type}' started",
        "task_id": hashlib.md5(f"{task_type}_{time.time()}".encode()).hexdigest()[:8],
        "status": "queued"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info") 